"""
Local CLI RAG chatbot using the OpenAI API (GPT-4 class models).
- Generates SQL text without executing it.
- Uses OpenAI embeddings + chat completions instead of a local LLM server.
"""

import argparse
import json
import os
from datetime import datetime
from typing import List, Tuple

import numpy as np
from dotenv import load_dotenv
from openai import OpenAI

load_dotenv()

RAG_INDEX_PATH = os.getenv("RAG_INDEX_PATH", "rag_index.json")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_BASE_URL = os.getenv("OPENAI_BASE_URL")  # Optional (e.g., Azure)
OPENAI_EMBED_MODEL = os.getenv("OPENAI_EMBED_MODEL", "text-embedding-3-small")
OPENAI_CHAT_MODEL = os.getenv("OPENAI_CHAT_MODEL", "gpt-4o")
OPENAI_TIMEOUT = float(os.getenv("OPENAI_TIMEOUT", "60"))

client = OpenAI(api_key=OPENAI_API_KEY, base_url=OPENAI_BASE_URL, timeout=OPENAI_TIMEOUT)


def load_rag_index(path: str) -> List[dict]:
    if not os.path.exists(path):
        raise FileNotFoundError(f"RAG index not found: {path}")
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)


def cosine(a, b) -> float:
    a = np.array(a, dtype=float)
    b = np.array(b, dtype=float)
    denom = (np.linalg.norm(a) * np.linalg.norm(b)) + 1e-8
    return float(np.dot(a, b) / denom)


def get_embedding(text: str) -> List[float]:
    resp = client.embeddings.create(model=OPENAI_EMBED_MODEL, input=text)
    return resp.data[0].embedding


def rag_retrieve(question: str, rag_index: List[dict], top_k: int = 3) -> List[dict]:
    q_emb = get_embedding(question)

    scored = []
    for item in rag_index:
        score = cosine(q_emb, item.get("embedding", []))
        scored.append((score, item))

    scored.sort(key=lambda x: x[0], reverse=True)
    return [s[1] for s in scored[:top_k]]


def format_context_blocks(contexts: List[dict]) -> Tuple[str, List[dict]]:
    ctx_blocks = []
    tables = []

    for context in contexts:
        ctx_blocks.append(context.get("text", ""))

        table_name = context.get("table_name", "")
        columns = ""
        for line in context.get("text", "").split("\n"):
            if line.startswith("Columns:"):
                columns = line.replace("Columns:", "").strip()
                break

        tables.append({"table": table_name, "columns": columns})

    return "\n\n---\n\n".join(ctx_blocks), tables


def generate_sql(question: str, rag_index: List[dict]) -> Tuple[str, List[dict]]:
    contexts = rag_retrieve(question, rag_index, top_k=3)
    ctx_text, tables = format_context_blocks(contexts)

    prompt = f"""
You are an expert MySQL assistant for the game Mafia42.

You are given context about the database schema.
Use ONLY the tables and columns that are consistent with this context.
Do NOT invent any new table or column.
Write a single valid MySQL SELECT query. No comments, no markdown, no explanation.

[CONTEXT]
{ctx_text}

[QUESTION]
{question}

[OUTPUT RULES]
- Output ONLY raw SQL.
- Do NOT wrap in ```sql ``` or any code fences.
- Use proper table and column names based on the context.
"""

    completion = client.chat.completions.create(
        model=OPENAI_CHAT_MODEL,
        messages=[
            {"role": "system", "content": "You are an expert MySQL assistant."},
            {"role": "user", "content": prompt},
        ],
        temperature=0,
    )

    content = completion.choices[0].message.content or ""
    sql = content.replace("```sql", "").replace("```", "").replace("`", "").strip()
    return sql, tables


def main() -> None:
    parser = argparse.ArgumentParser(description="OpenAI ê¸°ë°˜ ë¡œì»¬ RAG SQL ìƒì„± CLI (ì¿¼ë¦¬ ì‹¤í–‰ ì—†ìŒ).")
    parser.add_argument(
        "--rag-index",
        default=RAG_INDEX_PATH,
        help="Path to rag_index.json generated by build_rag_index.py",
    )
    args = parser.parse_args()

    if not OPENAI_API_KEY:
        print("âŒ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
        return

    try:
        rag_index = load_rag_index(args.rag_index)
    except FileNotFoundError as exc:
        print(f"âŒ {exc}")
        return

    print("ğŸ’¬ ë¡œì»¬ RAG ì±—ë´‡ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤. 'exit' ë˜ëŠ” 'quit'ìœ¼ë¡œ ì¢…ë£Œí•˜ì„¸ìš”.")
    print(
        f"ğŸ“š ìŠ¤í‚¤ë§ˆ ì—”íŠ¸ë¦¬: {len(rag_index)}ê°œ (chat_model={OPENAI_CHAT_MODEL}, embed_model={OPENAI_EMBED_MODEL})"
    )
    base_display = OPENAI_BASE_URL if OPENAI_BASE_URL else "https://api.openai.com"
    print(f"ğŸ”Œ ëŒ€ìƒ ì—”ë“œí¬ì¸íŠ¸: {base_display}")

    while True:
        question = input("ì§ˆë¬¸> ").strip()
        if not question:
            continue
        if question.lower() in {"exit", "quit"}:
            break

        timestamp = datetime.now().isoformat(timespec="seconds")
        print(f"\n[{timestamp}] SQL ìƒì„± ì¤‘...\n")

        try:
            sql, tables = generate_sql(question, rag_index)
        except Exception as exc:
            print(f"âŒ SQL ìƒì„± ì‹¤íŒ¨: {exc}")
            continue

        print("--- ì œì•ˆëœ SQL ------------------------------")
        print(sql)
        print("-------------------------------------------")

        if tables:
            used = ", ".join([t["table"] for t in tables if t.get("table")])
            if used:
                print(f"ğŸ“Š ì‚¬ìš©ëœ í…Œì´ë¸”: {used}")
        print()


if __name__ == "__main__":
    main()
